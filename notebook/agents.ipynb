{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multi-Agent Financial Advisory System using LangGraph 1.04\n",
        "\n",
        "This notebook implements a sophisticated multi-agent system for financial advisory services with:\n",
        "- **6 Specialized Agents**: Each handling specific financial domains\n",
        "- **Intelligent Routing**: Automatic query classification\n",
        "- **RAG Integration**: Retrieval-Augmented Generation for context-aware responses\n",
        "- **Modular Architecture**: Easy to extend and customize\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Installation and Setup\n",
        "\n",
        "Install all required dependencies for the multi-agent system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install core dependencies\n",
        "!pip install -q langgraph==0.2.45\n",
        "!pip install -q langchain==0.3.7\n",
        "!pip install -q langchain-core==0.3.15\n",
        "!pip install -q langchain-openai==0.2.8\n",
        "!pip install -q langchain-anthropic==0.2.4\n",
        "\n",
        "# Install vector store and embedding dependencies (optional)\n",
        "!pip install -q faiss-cpu==1.8.0\n",
        "!pip install -q chromadb==0.5.18\n",
        "!pip install -q sentence-transformers==3.3.1\n",
        "\n",
        "print(\"✅ All dependencies installed successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Import Required Libraries\n",
        "\n",
        "Import all necessary modules for building the multi-agent system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core Python libraries\n",
        "from typing import TypedDict, Annotated, Sequence, Literal\n",
        "import operator\n",
        "import os\n",
        "\n",
        "# LangGraph and LangChain\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# LLM imports (uncomment the one you'll use)\n",
        "# from langchain_openai import ChatOpenAI\n",
        "# from langchain_anthropic import ChatAnthropic\n",
        "\n",
        "# Vector store imports (optional)\n",
        "# from langchain_community.vectorstores import FAISS, Chroma\n",
        "# from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "print(\"✅ All imports loaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Configure API Keys\n",
        "\n",
        "Set up your LLM provider API keys. **Note**: Never commit API keys to version control!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Option 1: Set API keys as environment variables\n",
        "# os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key\"\n",
        "# os.environ[\"ANTHROPIC_API_KEY\"] = \"your-anthropic-api-key\"\n",
        "\n",
        "# Option 2: Load from .env file (recommended)\n",
        "# from dotenv import load_dotenv\n",
        "# load_dotenv()\n",
        "\n",
        "print(\"✅ API keys configured (or using mock LLM for testing)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Define Agent State\n",
        "\n",
        "The `AgentState` is a shared data structure that flows through the entire workflow, tracking conversation history, routing decisions, and context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AgentState(TypedDict):\n",
        "    \"\"\"\n",
        "    Shared state across all agents in the workflow.\n",
        "    \n",
        "    Attributes:\n",
        "        messages: Conversation history (accumulated using operator.add)\n",
        "        next_agent: Name of the agent that should handle the query\n",
        "        user_query: Original user question\n",
        "        context: Additional data (user profile, portfolio, retrieved docs)\n",
        "        agent_responses: Dictionary storing each agent's response\n",
        "        confidence_score: Router's confidence in agent selection\n",
        "    \"\"\"\n",
        "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
        "    next_agent: str\n",
        "    user_query: str\n",
        "    context: dict\n",
        "    agent_responses: dict\n",
        "    confidence_score: float\n",
        "\n",
        "print(\"✅ AgentState defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Base Agent Class\n",
        "\n",
        "The `BaseFinancialAgent` provides common functionality for all specialized agents, including RAG retrieval and response generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BaseFinancialAgent:\n",
        "    \"\"\"Base class for all financial agents with common RAG functionality\"\"\"\n",
        "    \n",
        "    def __init__(self, name: str, llm, retriever=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            name: Agent identifier\n",
        "            llm: Language model instance\n",
        "            retriever: Vector store retriever for RAG (optional)\n",
        "        \"\"\"\n",
        "        self.name = name\n",
        "        self.llm = llm\n",
        "        self.retriever = retriever\n",
        "        self.system_prompt = self._get_system_prompt()\n",
        "    \n",
        "    def _get_system_prompt(self) -> str:\n",
        "        \"\"\"Override in subclasses to define agent-specific behavior\"\"\"\n",
        "        return f\"You are a {self.name} specialized in financial services.\"\n",
        "    \n",
        "    def retrieve_context(self, query: str) -> list:\n",
        "        \"\"\"\n",
        "        RAG retrieval - fetch relevant documents from vector store\n",
        "        \n",
        "        Args:\n",
        "            query: User's question\n",
        "            \n",
        "        Returns:\n",
        "            List of relevant document contents\n",
        "        \"\"\"\n",
        "        if self.retriever:\n",
        "            docs = self.retriever.get_relevant_documents(query)\n",
        "            return [doc.page_content for doc in docs]\n",
        "        return []\n",
        "    \n",
        "    def process(self, state: AgentState) -> AgentState:\n",
        "        \"\"\"\n",
        "        Main processing logic for the agent\n",
        "        \n",
        "        Flow: Retrieve Context → Build Prompt → Generate Response → Update State\n",
        "        \"\"\"\n",
        "        query = state[\"user_query\"]\n",
        "        \n",
        "        # Step 1: RAG - Retrieve relevant context\n",
        "        context_docs = self.retrieve_context(query)\n",
        "        context_str = \"\\n\\n\".join(context_docs) if context_docs else \"No additional context available.\"\n",
        "        \n",
        "        # Step 2: Build prompt with context\n",
        "        prompt = ChatPromptTemplate.from_messages([\n",
        "            (\"system\", self.system_prompt),\n",
        "            (\"human\", f\"Context:\\n{context_str}\\n\\nUser Query: {query}\")\n",
        "        ])\n",
        "        \n",
        "        # Step 3: Generate response\n",
        "        chain = prompt | self.llm | StrOutputParser()\n",
        "        response = chain.invoke({\"query\": query})\n",
        "        \n",
        "        # Step 4: Update state\n",
        "        state[\"messages\"].append(AIMessage(content=response, name=self.name))\n",
        "        state[\"agent_responses\"][self.name] = response\n",
        "        \n",
        "        return state\n",
        "\n",
        "print(\"✅ BaseFinancialAgent class defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Specialized Agent Implementations\n",
        "\n",
        "Each agent inherits from `BaseFinancialAgent` and defines its own specialized system prompt and behavior."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.1 Finance Q&A Agent\n",
        "Handles general financial education queries and concept explanations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FinanceQAAgent(BaseFinancialAgent):\n",
        "    \"\"\"Handles general financial education queries\"\"\"\n",
        "    \n",
        "    def _get_system_prompt(self) -> str:\n",
        "        return \"\"\"You are a Finance Q&A Agent specializing in financial education.\n",
        "        \n",
        "Your role:\n",
        "- Answer general questions about financial concepts, terminology, and principles\n",
        "- Provide clear, educational explanations suitable for various knowledge levels\n",
        "- Use examples and analogies to clarify complex topics\n",
        "- Maintain accuracy and cite sources when providing specific data\n",
        "\n",
        "Keep responses concise yet comprehensive.\"\"\"\n",
        "\n",
        "print(\"✅ FinanceQAAgent defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.2 Portfolio Analysis Agent\n",
        "Reviews and analyzes investment portfolios for optimization opportunities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PortfolioAnalysisAgent(BaseFinancialAgent):\n",
        "    \"\"\"Reviews and analyzes user portfolios\"\"\"\n",
        "    \n",
        "    def _get_system_prompt(self) -> str:\n",
        "        return \"\"\"You are a Portfolio Analysis Agent specializing in investment portfolio review.\n",
        "        \n",
        "Your role:\n",
        "- Analyze portfolio composition, diversification, and risk exposure\n",
        "- Identify potential issues like concentration risk or misalignment with goals\n",
        "- Provide actionable insights for portfolio optimization\n",
        "- Consider risk tolerance, time horizon, and financial goals\n",
        "- Use data from the context to provide specific recommendations\n",
        "\n",
        "Be thorough but accessible in your analysis.\"\"\"\n",
        "\n",
        "print(\"✅ PortfolioAnalysisAgent defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.3 Market Analysis Agent\n",
        "Provides real-time market insights and trend analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MarketAnalysisAgent(BaseFinancialAgent):\n",
        "    \"\"\"Provides real-time market insights\"\"\"\n",
        "    \n",
        "    def _get_system_prompt(self) -> str:\n",
        "        return \"\"\"You are a Market Analysis Agent specializing in market insights and trends.\n",
        "        \n",
        "Your role:\n",
        "- Analyze current market conditions and trends\n",
        "- Provide context for recent market movements\n",
        "- Explain sector performance and economic indicators\n",
        "- Connect market events to potential portfolio impacts\n",
        "- Use real-time data from the context when available\n",
        "\n",
        "Focus on actionable insights rather than predictions.\"\"\"\n",
        "\n",
        "print(\"✅ MarketAnalysisAgent defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.4 Goal Planning Agent\n",
        "Assists with financial goal setting, planning, and milestone tracking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GoalPlanningAgent(BaseFinancialAgent):\n",
        "    \"\"\"Assists with financial goal setting and planning\"\"\"\n",
        "    \n",
        "    def _get_system_prompt(self) -> str:\n",
        "        return \"\"\"You are a Goal Planning Agent specializing in financial goal setting.\n",
        "        \n",
        "Your role:\n",
        "- Help users define and structure financial goals (retirement, education, home purchase)\n",
        "- Calculate required savings rates and timelines\n",
        "- Suggest appropriate investment strategies for different goal timeframes\n",
        "- Break down complex long-term goals into actionable steps\n",
        "- Consider inflation, expected returns, and risk factors\n",
        "\n",
        "Be encouraging while maintaining realistic expectations.\"\"\"\n",
        "\n",
        "print(\"✅ GoalPlanningAgent defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.5 News Synthesizer Agent\n",
        "Summarizes and contextualizes financial news for users."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NewsSynthesizerAgent(BaseFinancialAgent):\n",
        "    \"\"\"Summarizes and contextualizes financial news\"\"\"\n",
        "    \n",
        "    def _get_system_prompt(self) -> str:\n",
        "        return \"\"\"You are a News Synthesizer Agent specializing in financial news analysis.\n",
        "        \n",
        "Your role:\n",
        "- Summarize complex financial news into digestible insights\n",
        "- Contextualize news events within broader market trends\n",
        "- Explain potential impacts on different investment types\n",
        "- Filter noise from signal in financial media\n",
        "- Connect news to user's potential interests or portfolio\n",
        "\n",
        "Remain objective and avoid sensationalism.\"\"\"\n",
        "\n",
        "print(\"✅ NewsSynthesizerAgent defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.6 Tax Education Agent\n",
        "Explains tax concepts, account types, and strategies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TaxEducationAgent(BaseFinancialAgent):\n",
        "    \"\"\"Explains tax concepts and account types\"\"\"\n",
        "    \n",
        "    def _get_system_prompt(self) -> str:\n",
        "        return \"\"\"You are a Tax Education Agent specializing in tax concepts and account types.\n",
        "        \n",
        "Your role:\n",
        "- Explain tax-advantaged accounts (401k, IRA, Roth IRA, HSA, 529)\n",
        "- Clarify tax implications of different investment strategies\n",
        "- Educate on tax-loss harvesting, capital gains, and deductions\n",
        "- Compare tax treatment of different account types\n",
        "- Provide general tax education (not personalized tax advice)\n",
        "\n",
        "Always remind users to consult a tax professional for specific situations.\"\"\"\n",
        "\n",
        "print(\"✅ TaxEducationAgent defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Router Agent\n",
        "\n",
        "The router analyzes user queries and intelligently routes them to the most appropriate specialized agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RouterAgent:\n",
        "    \"\"\"Routes user queries to the most appropriate agent(s)\"\"\"\n",
        "    \n",
        "    def __init__(self, llm):\n",
        "        self.llm = llm\n",
        "        self.routing_prompt = ChatPromptTemplate.from_messages([\n",
        "            (\"system\", \"\"\"You are a routing agent for a financial advisory system. \n",
        "            Analyze the user query and determine which agent should handle it.\n",
        "            \n",
        "            Available agents:\n",
        "            - finance_qa: General financial education and concepts\n",
        "            - portfolio_analysis: Portfolio review and optimization\n",
        "            - market_analysis: Market trends and insights\n",
        "            - goal_planning: Financial goal setting and planning\n",
        "            - news_synthesizer: Financial news summaries and context\n",
        "            - tax_education: Tax concepts and account types\n",
        "            \n",
        "            Respond with ONLY the agent name, nothing else.\"\"\"),\n",
        "            (\"human\", \"User query: {query}\")\n",
        "        ])\n",
        "    \n",
        "    def route(self, state: AgentState) -> AgentState:\n",
        "        \"\"\"Determine which agent should handle the query\"\"\"\n",
        "        chain = self.routing_prompt | self.llm | StrOutputParser()\n",
        "        next_agent = chain.invoke({\"query\": state[\"user_query\"]}).strip().lower()\n",
        "        \n",
        "        # Validate agent name\n",
        "        valid_agents = [\n",
        "            \"finance_qa\", \"portfolio_analysis\", \"market_analysis\",\n",
        "            \"goal_planning\", \"news_synthesizer\", \"tax_education\"\n",
        "        ]\n",
        "        \n",
        "        if next_agent not in valid_agents:\n",
        "            next_agent = \"finance_qa\"  # Default fallback\n",
        "        \n",
        "        state[\"next_agent\"] = next_agent\n",
        "        state[\"confidence_score\"] = 0.85  # Placeholder - implement actual scoring\n",
        "        \n",
        "        return state\n",
        "\n",
        "print(\"✅ RouterAgent defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Workflow Orchestrator\n",
        "\n",
        "The `FinancialAdvisoryWorkflow` class builds and manages the LangGraph workflow, connecting all agents into a cohesive system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FinancialAdvisoryWorkflow:\n",
        "    \"\"\"Main workflow orchestrator using LangGraph\"\"\"\n",
        "    \n",
        "    def __init__(self, llm, retrievers: dict = None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            llm: Language model instance\n",
        "            retrievers: Dict mapping agent names to their retrievers\n",
        "        \"\"\"\n",
        "        self.llm = llm\n",
        "        self.retrievers = retrievers or {}\n",
        "        \n",
        "        # Initialize all specialized agents\n",
        "        self.agents = {\n",
        "            \"finance_qa\": FinanceQAAgent(\n",
        "                \"Finance Q&A\", llm, self.retrievers.get(\"finance_qa\")\n",
        "            ),\n",
        "            \"portfolio_analysis\": PortfolioAnalysisAgent(\n",
        "                \"Portfolio Analysis\", llm, self.retrievers.get(\"portfolio_analysis\")\n",
        "            ),\n",
        "            \"market_analysis\": MarketAnalysisAgent(\n",
        "                \"Market Analysis\", llm, self.retrievers.get(\"market_analysis\")\n",
        "            ),\n",
        "            \"goal_planning\": GoalPlanningAgent(\n",
        "                \"Goal Planning\", llm, self.retrievers.get(\"goal_planning\")\n",
        "            ),\n",
        "            \"news_synthesizer\": NewsSynthesizerAgent(\n",
        "                \"News Synthesizer\", llm, self.retrievers.get(\"news_synthesizer\")\n",
        "            ),\n",
        "            \"tax_education\": TaxEducationAgent(\n",
        "                \"Tax Education\", llm, self.retrievers.get(\"tax_education\")\n",
        "            ),\n",
        "        }\n",
        "        \n",
        "        self.router = RouterAgent(llm)\n",
        "        self.graph = self._build_graph()\n",
        "    \n",
        "    def _build_graph(self) -> StateGraph:\n",
        "        \"\"\"Construct the LangGraph workflow\"\"\"\n",
        "        workflow = StateGraph(AgentState)\n",
        "        \n",
        "        # Add router node\n",
        "        workflow.add_node(\"router\", self.router.route)\n",
        "        \n",
        "        # Add agent nodes\n",
        "        for name, agent in self.agents.items():\n",
        "            workflow.add_node(name, agent.process)\n",
        "        \n",
        "        # Set entry point\n",
        "        workflow.set_entry_point(\"router\")\n",
        "        \n",
        "        # Add conditional edges from router to agents\n",
        "        workflow.add_conditional_edges(\n",
        "            \"router\",\n",
        "            lambda state: state[\"next_agent\"],\n",
        "            {name: name for name in self.agents.keys()}\n",
        "        )\n",
        "        \n",
        "        # All agents lead to END\n",
        "        for name in self.agents.keys():\n",
        "            workflow.add_edge(name, END)\n",
        "        \n",
        "        return workflow.compile()\n",
        "    \n",
        "    def invoke(self, user_query: str, context: dict = None) -> dict:\n",
        "        \"\"\"\n",
        "        Execute the workflow for a user query\n",
        "        \n",
        "        Args:\n",
        "            user_query: The user's question\n",
        "            context: Additional context (user profile, portfolio data, etc.)\n",
        "        \n",
        "        Returns:\n",
        "            Final state with agent responses\n",
        "        \"\"\"\n",
        "        initial_state = {\n",
        "            \"messages\": [HumanMessage(content=user_query)],\n",
        "            \"next_agent\": \"\",\n",
        "            \"user_query\": user_query,\n",
        "            \"context\": context or {},\n",
        "            \"agent_responses\": {},\n",
        "            \"confidence_score\": 0.0\n",
        "        }\n",
        "        \n",
        "        result = self.graph.invoke(initial_state)\n",
        "        return result\n",
        "\n",
        "print(\"✅ FinancialAdvisoryWorkflow defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Initialize LLM\n",
        "\n",
        "Choose your LLM provider. Uncomment the one you want to use, or use the MockLLM for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Option 1: OpenAI\n",
        "# llm = ChatOpenAI(model=\"gpt-4\", temperature=0.7)\n",
        "\n",
        "# Option 2: Anthropic Claude\n",
        "# llm = ChatAnthropic(model=\"claude-3-5-sonnet-20241022\", temperature=0.7)\n",
        "\n",
        "# Option 3: Mock LLM for testing (no API key required)\n",
        "class MockLLM:\n",
        "    \"\"\"Mock LLM for demonstration and testing purposes\"\"\"\n",
        "    \n",
        "    def invoke(self, prompt):\n",
        "        # Simple routing logic for demonstration\n",
        "        if isinstance(prompt, dict) and \"query\" in prompt:\n",
        "            query = prompt[\"query\"].lower()\n",
        "            \n",
        "            if \"portfolio\" in query or \"investment\" in query:\n",
        "                return \"portfolio_analysis\"\n",
        "            elif \"market\" in query or \"stock\" in query:\n",
        "                return \"market_analysis\"\n",
        "            elif \"retirement\" in query or \"goal\" in query or \"plan\" in query:\n",
        "                return \"goal_planning\"\n",
        "            elif \"news\" in query or \"latest\" in query:\n",
        "                return \"news_synthesizer\"\n",
        "            elif \"tax\" in query or \"ira\" in query or \"401k\" in query:\n",
        "                return \"tax_education\"\n",
        "            else:\n",
        "                return \"finance_qa\"\n",
        "        \n",
        "        return \"This is a mock response. Based on your query, I would provide detailed financial advice here.\"\n",
        "\n",
        "llm = MockLLM()\n",
        "print(\"✅ LLM initialized (using MockLLM for testing)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Optional: Set Up RAG Retrievers\n",
        "\n",
        "Configure vector stores for each agent. This is optional but highly recommended for production use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Setting up a simple FAISS retriever\n",
        "# Uncomment and modify for your use case\n",
        "\n",
        "\"\"\"\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "\n",
        "# Initialize embeddings\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Example: Create a retriever for finance Q&A\n",
        "# 1. Load your documents\n",
        "# loader = TextLoader(\"path/to/your/finance_docs.txt\")\n",
        "# documents = loader.load()\n",
        "\n",
        "# 2. Split into chunks\n",
        "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "# chunks = text_splitter.split_documents(documents)\n",
        "\n",
        "# 3. Create vector store\n",
        "# vectorstore = FAISS.from_documents(chunks, embeddings)\n",
        "\n",
        "# 4. Create retriever\n",
        "# finance_qa_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "# Repeat for other agents...\n",
        "retrievers = {\n",
        "    # \"finance_qa\